{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b0ed7218-226d-4b60-b1e4-d83f4a48cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "98eebc74-01d2-4eea-9694-c939e96e00fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3d65d95a-43b2-41c6-9292-a9e396ca1af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27480, 4)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e87cf590-0826-4e21-9c5f-a0a80a07c8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6e0c6d75b1</td>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>fun</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27474</th>\n",
       "      <td>b78ec00df5</td>\n",
       "      <td>enjoy ur night</td>\n",
       "      <td>enjoy</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27475</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16363 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2      088c60f138                          my boss is bullying me...   \n",
       "3      9642c003ef                     what interview! leave me alone   \n",
       "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "6      6e0c6d75b1  2am feedings for the baby are fun when he is a...   \n",
       "...           ...                                                ...   \n",
       "27474  b78ec00df5                                     enjoy ur night   \n",
       "27475  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27476  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27477  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27478  ed167662a5                         But it was worth it  ****.   \n",
       "\n",
       "                    selected_text sentiment  \n",
       "1                        Sooo SAD  negative  \n",
       "2                     bullying me  negative  \n",
       "3                  leave me alone  negative  \n",
       "4                   Sons of ****,  negative  \n",
       "6                             fun  positive  \n",
       "...                           ...       ...  \n",
       "27474                       enjoy  positive  \n",
       "27475                      d lost  negative  \n",
       "27476               , don`t force  negative  \n",
       "27477   Yay good for both of you.  positive  \n",
       "27478  But it was worth it  ****.  positive  \n",
       "\n",
       "[16363 rows x 4 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtre le DataFrame pr éliminer les lignes où 'neutral' apparait : \n",
    "df_filtered = df[df['sentiment'] != 'neutral']\n",
    "\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eba8a311-6947-4693-a7d9-b4a499e60353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16363, 4)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "33f6237a-30e8-437d-b3d5-a7c345b8e7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    52.447595\n",
       "negative    47.552405\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcule la fréqce des sentimts :\n",
    "sentiment = df_filtered['sentiment'].value_counts()\n",
    "\n",
    "# Calcule le % de chaq sentimt :\n",
    "sentiment_pourcent = (sentiment / sentiment.sum()) * 100\n",
    "\n",
    "sentiment_pourcent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d72e04f3-e0d9-4082-bad8-d0e068036e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sebla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sebla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sebla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Téléchrge les ressrces nécessaires :\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialise le lemmatiseur et les stopwords :\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('french'))\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "# ¨Prétraitemt du texte :\n",
    "def clean(text):\n",
    "    \"\"\"\n",
    "    Fonction de nettoyage d'un texte : \n",
    "    - Tokenisation\n",
    "    - Conversion en minuscules\n",
    "    - Suppression des stopwords et de la ponctuation\n",
    "    - Application du lemmatiseur\n",
    "\n",
    "    :param text: Texte à nettoyer (str)\n",
    "    :return: Texte nettoyé sous forme de tokens (str)\n",
    "    \"\"\"\n",
    "\n",
    "    # Tokenisat° :\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Cvers° en minuscules et suppress° des mots vides :\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha() and token.lower() not in stop_words]\n",
    "    \n",
    "    # Recposit° du texte nettoyé ss frme de chaîne avec des espaces entre les tokens :\n",
    "    cleaned_text = \" \".join(tokens)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "435c4884-eecc-4704-8b3e-a7f8aa542154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original:\n",
      "You are better when I am well !\n",
      "\n",
      "Texte nettoyé (lemmatisé):\n",
      "you are better when i am well\n"
     ]
    }
   ],
   "source": [
    "# Test :\n",
    "texte = \"You are better when I am well !\"\n",
    "texte_nettoye = clean(texte)\n",
    "\n",
    "print(\"Texte original:\")\n",
    "print(texte)\n",
    "\n",
    "print(\"\\nTexte nettoyé (lemmatisé):\")\n",
    "print(texte_nettoye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3c93eb10-1b60-466d-81e9-7f3e21effedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise du stemmer :\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def clean_stemmer(text):\n",
    "    \"\"\"\n",
    "    Fonction de nettoyage d'un texte avec un stemmer :\n",
    "    - Tokenisation\n",
    "    - Conversion en minuscules\n",
    "    - Suppression des stopwords et de la ponctuation\n",
    "    - Application du stemmer\n",
    "\n",
    "    :param text: Texte à nettoyer (str)\n",
    "    :return: Texte nettoyé sous forme de tokens (str)\n",
    "    \"\"\"\n",
    "    # Tokenisat° des mots :\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Prétraitemt des tokens : suppress° des mots vides, ponctuat° et convers° en minuscules :\n",
    "    tokens = [stemmer.stem(token.lower()) for token in tokens if token.isalpha() and token.lower() not in stop_words]\n",
    "    \n",
    "    # Recposit° du texte nettoyé ss frme de chaîne avec des espaces entre les tokens :\n",
    "    cleaned_text = \" \".join(tokens)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "50507814-27e8-48d3-9489-a922dc8ed4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original:\n",
      "You are better when I am well !\n",
      "\n",
      "Texte nettoyé (stemmer):\n",
      "you are better when i am well\n"
     ]
    }
   ],
   "source": [
    "# Test :\n",
    "texte = \"You are better when I am well !\"\n",
    "texte_nettoye = clean(texte)\n",
    "\n",
    "print(\"Texte original:\")\n",
    "print(texte)\n",
    "\n",
    "print(\"\\nTexte nettoyé (stemmer):\")\n",
    "print(texte_nettoye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f0b6153d-f8cf-437d-9a4b-8ecea66defa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise le lemmatiseur :\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Récupére les stopwords anglais :\n",
    "stopwordsenglish = set(stopwords.words('english'))\n",
    "\n",
    "# Ponctuat° à exclure :\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "def clean(text):\n",
    "    \"\"\"\n",
    "    Fonction de nettoyage d'un texte :\n",
    "    - Tokenisation\n",
    "    - Conversion en minuscules\n",
    "    - Suppression des stopwords en français et anglais\n",
    "    - Suppression de la ponctuation\n",
    "    - Application du lemmatiseur\n",
    "\n",
    "    :param text: Texte à nettoyer (str)\n",
    "    :return: Texte nettoyé sous forme de tokens (str)\n",
    "    \"\"\"\n",
    "    # Tokenisat° des mots :\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Prétraitemt des tokens :\n",
    "    # - Suppress° des mots vides (stopwords en anglais et en français)\n",
    "    # - Suppress° des signes de ponctuat°\n",
    "    # - Convers° en minuscules et lemmatisat°\n",
    "    tokens = [\n",
    "        lemmatizer.lemmatize(token.lower()) \n",
    "        for token in tokens \n",
    "        if token.isalpha() and token.lower() not in stopwordsenglish and token.lower() not in stopwords.words('french') and token not in punctuation\n",
    "    ]\n",
    "    \n",
    "    # Recpose le texte nettoyé ss frme de chaîne avec des espaces entre les tokens :\n",
    "    cleaned_text = \" \".join(tokens)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9fd69443-5848-4de0-82dd-ba08a57048d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original:\n",
      "The children are eating apples, and they are playing in the park!\n",
      "\n",
      "Texte nettoyé:\n",
      "child eating apple playing park\n"
     ]
    }
   ],
   "source": [
    "# Test :\n",
    "texte = \"The children are eating apples, and they are playing in the park!\"\n",
    "\n",
    "# Appliq la fct° clean :\n",
    "texte_nettoye = clean(texte)\n",
    "\n",
    "print(\"Texte original:\")\n",
    "print(texte)\n",
    "\n",
    "print(\"\\nTexte nettoyé:\")\n",
    "print(texte_nettoye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6000746e-109e-4cfa-a755-75e6136e7b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>responded going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>sooo sad miss san diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bos bullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>interview leave alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>son put release already bought</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                I`d have responded, if I were going   \n",
       "1      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                          my boss is bullying me...   \n",
       "3                     what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                            clean  \n",
       "0                 responded going  \n",
       "1         sooo sad miss san diego  \n",
       "2                    bos bullying  \n",
       "3           interview leave alone  \n",
       "4  son put release already bought  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appliq la fct° 'clean' à chaq élémt de la colonne 'text'\n",
    "df['clean'] = df['text'].apply(clean)\n",
    "\n",
    "# Affiche le DataFrame avec la nvelle colonne 'clean' :\n",
    "df[['text', 'clean']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c1408b1d-53a5-4e10-b647-2cca5765aece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement (X_train, y_train): 20610\n",
      "Taille de l'ensemble de test (X_test, y_test): 6870\n"
     ]
    }
   ],
   "source": [
    "# Copie la colonne 'clean' ds 1 série X (caractéristiq d'entrée) :\n",
    "X = df['clean']\n",
    "\n",
    "# Copie la colonne 'sentimt' ds 1 série y (labels de sortie) :\n",
    "y = df['sentiment']\n",
    "\n",
    "# Appliq train-test split :\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=32)\n",
    "\n",
    "print(\"Taille de l'ensemble d'entraînement (X_train, y_train):\", len(X_train))\n",
    "print(\"Taille de l'ensemble de test (X_test, y_test):\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "324b8659-f1b2-4906-8d5c-2db16b8c9f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy du modèle : 0.6902\n"
     ]
    }
   ],
   "source": [
    "# Créer 1 mdèle CountVectorizer :\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Entraîne le mdèle sur X_train et créer la matrice de caractéristiq X_train_CV :\n",
    "X_train_CV = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Créer la matrice de caractéristiq X_test_CV en utilisant le même mdèle sans réentraîner :\n",
    "X_test_CV = vectorizer.transform(X_test)\n",
    "\n",
    "# Entraîner 1 mdèle de régress° logistiq sur les données vectorisées\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_CV, y_train)\n",
    "\n",
    "# Prédis sur l'ensble de test :\n",
    "y_pred_CV = model.predict(X_test_CV)\n",
    "\n",
    "# Évaluat° du mdèle :\n",
    "accuracy_CV = accuracy_score(y_test, y_pred_CV)\n",
    "print(f\"Accuracy du modèle : {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c0240837-a542-4cf6-aaae-d373ef970d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy du modèle : 0.6902\n",
      "Résultats pour CountVectorizer :\n",
      "Accuracy (CountVectorizer) : 0.6902\n",
      "\n",
      "Classification Report (CountVectorizer) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.61      0.65      1944\n",
      "     neutral       0.64      0.72      0.68      2772\n",
      "    positive       0.75      0.72      0.74      2154\n",
      "\n",
      "    accuracy                           0.69      6870\n",
      "   macro avg       0.70      0.68      0.69      6870\n",
      "weighted avg       0.69      0.69      0.69      6870\n",
      "\n",
      "\n",
      "Résultats pour TfidfVectorizer :\n",
      "Accuracy (TfidfVectorizer) : 0.5622\n",
      "\n",
      "Classification Report (TfidfVectorizer) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.32      0.46      1944\n",
      "     neutral       0.48      0.94      0.64      2772\n",
      "    positive       0.90      0.29      0.44      2154\n",
      "\n",
      "    accuracy                           0.56      6870\n",
      "   macro avg       0.73      0.52      0.51      6870\n",
      "weighted avg       0.71      0.56      0.53      6870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Créer 1 mdèle TfidfVectorizer :\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Entraîne le mdèle sur X_train et créer la matrice de caractéristiq X_train_CV :\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Créer la matrice de caractéristiq X_test_CV en utilisant le même mdèle sans réentraîner :\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Entraîner 1 mdèle de régress° logistiq sur les données vectorisées\n",
    "model_tfidf = LogisticRegression(max_iter=1000)\n",
    "model_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Prédis sur l'ensble de test :\n",
    "y_pred_tfidf = model.predict(X_test_tfidf)\n",
    "\n",
    "# Évaluat° du mdèle :\n",
    "accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "print(f\"Accuracy du modèle : {accuracy:.4f}\")\n",
    "\n",
    "# Affiche des résultats de cparais° :\n",
    "print(\"Résultats pour CountVectorizer :\")\n",
    "print(f\"Accuracy (CountVectorizer) : {accuracy_CV:.4f}\")\n",
    "print(\"\\nClassification Report (CountVectorizer) :\")\n",
    "print(classification_report(y_test, y_pred_CV))\n",
    "\n",
    "print(\"\\nRésultats pour TfidfVectorizer :\")\n",
    "print(f\"Accuracy (TfidfVectorizer) : {accuracy_tfidf:.4f}\")\n",
    "print(\"\\nClassification Report (TfidfVectorizer) :\")\n",
    "print(classification_report(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1fb153-01c3-4d34-9d1a-8ccafdbc5393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les meilleurs paramètres sont obtenus avec le modèle de CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bdf4bc8e-5d87-48b4-a2f6-575fadba7403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Meilleurs pramètres pr CountVectorizer :\n",
      "{'vectorizer__max_df': 0.75, 'vectorizer__min_df': 1, 'vectorizer__ngram_range': (1, 2), 'vectorizer__stop_words': 'english'}\n",
      "Meilleur score de validation : 0.6923\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "\n",
      "Meilleurs paramètres pour TfidfVectorizer :\n",
      "{'vectorizer__max_df': 0.75, 'vectorizer__min_df': 1, 'vectorizer__ngram_range': (1, 2), 'vectorizer__stop_words': 'english'}\n",
      "Meilleur score de validation : 0.6882\n"
     ]
    }
   ],
   "source": [
    "# Séparat° des données en jeu d'entraînemt et de test :\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=32)\n",
    "\n",
    "# Pramètres à tester pr CountVectorizer et TfidfVectorizer :\n",
    "param_grid_cv = {\n",
    "    'vectorizer__max_df': [0.75, 1.0],  # Ignore les mots apparaissant ds + de 75% des documts\n",
    "    'vectorizer__min_df': [1, 5],  # Ignore les mots apparaissant ds - de 5 documts\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],  # Unigrammes ou Bigrammes\n",
    "    'vectorizer__stop_words': ['english', None]  # Utilise les stopwords anglais ou pas\n",
    "}\n",
    "\n",
    "param_grid_tfidf = {\n",
    "    'vectorizer__max_df': [0.75, 1.0],\n",
    "    'vectorizer__min_df': [1, 5],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vectorizer__stop_words': ['english', None]\n",
    "}\n",
    "\n",
    "# Pipeline avec CountVectorizer :\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Créat° du Pipeline pr CountVectorizer :\n",
    "pipeline_cv = Pipeline([\n",
    "    ('vectorizer', count_vectorizer),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))  # Régress° logistiq\n",
    "])\n",
    "\n",
    "# GridSearchCV pr CountVectorizer avec Régress° logistiq :\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=pipeline_cv, \n",
    "    param_grid=param_grid_cv, \n",
    "    cv=5,  # 5-fold Cross-validat°\n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,  # Utiliser ts les cœurs de CPU\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Apprentissage avec GridSearchCV pr CountVectorizer :\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "# Affiche les meilleurs pramètres trvés :\n",
    "print(\"Meilleurs pramètres pr CountVectorizer :\")\n",
    "print(grid_search_cv.best_params_)\n",
    "print(f\"Meilleur score de validation : {grid_search_cv.best_score_:.4f}\")\n",
    "\n",
    "# Pipeline avec TfidfVectorizer :\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Créat° du Pipeline pr TfidfVectorizer :\n",
    "pipeline_tfidf = Pipeline([\n",
    "    ('vectorizer', tfidf_vectorizer),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))  # Régress° logistiq\n",
    "])\n",
    "\n",
    "# GridSearchCV pr TfidfVectorizer avec Régress° logistiq\n",
    "grid_search_tfidf = GridSearchCV(\n",
    "    estimator=pipeline_tfidf, \n",
    "    param_grid=param_grid_tfidf, \n",
    "    cv=5, \n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Apprentissage avec GridSearchCV pr TfidfVectorizer :\n",
    "grid_search_tfidf.fit(X_train, y_train)\n",
    "\n",
    "# Affiche les meilleurs pramètres trvés :\n",
    "print(\"\\nMeilleurs paramètres pour TfidfVectorizer :\")\n",
    "print(grid_search_tfidf.best_params_)\n",
    "print(f\"Meilleur score de validation : {grid_search_tfidf.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "506c5e88-1e7a-4160-9e2c-36a2024f4236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation Scores pour CountVectorizer :\n",
      "[0.68558952 0.69311014 0.6768559  0.69335274 0.68073751]\n",
      "Moyenne Cross-validation : 0.6859\n",
      "\n",
      "Cross-validation Scores pour TfidfVectorizer :\n",
      "[0.6780689  0.68753033 0.67564289 0.68680252 0.67540029]\n",
      "Moyenne Cross-validation : 0.6807\n"
     ]
    }
   ],
   "source": [
    "# Cross-validat° pr évaluer les mdèles afin de trver les meilleurs pramètres :\n",
    "# Cross-validat° pr CountVectorizer :\n",
    "cv_score_cv = cross_val_score(\n",
    "    LogisticRegression(max_iter=1000), \n",
    "    count_vectorizer.fit_transform(X_train), \n",
    "    y_train, \n",
    "    cv=5, \n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "print(\"\\nCross-validation Scores pour CountVectorizer :\")\n",
    "print(cv_score_cv)\n",
    "print(f\"Moyenne Cross-validation : {cv_score_cv.mean():.4f}\")\n",
    "\n",
    "\n",
    "# Cross-validat° pr TfidfVectorizer :\n",
    "cv_score_tfidf = cross_val_score(\n",
    "    LogisticRegression(max_iter=1000), \n",
    "    tfidf_vectorizer.fit_transform(X_train), \n",
    "    y_train, \n",
    "    cv=5, \n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "print(\"\\nCross-validation Scores pour TfidfVectorizer :\")\n",
    "print(cv_score_tfidf)\n",
    "print(f\"Moyenne Cross-validation : {cv_score_tfidf.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1262c000-4620-4c4d-8f6c-2a892cac2087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report pour TfidfVectorizer :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.59      0.65      1944\n",
      "     neutral       0.63      0.74      0.68      2772\n",
      "    positive       0.76      0.71      0.73      2154\n",
      "\n",
      "    accuracy                           0.69      6870\n",
      "   macro avg       0.70      0.68      0.69      6870\n",
      "weighted avg       0.70      0.69      0.69      6870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Entraînemt final sur le meilleur modèle :\n",
    "# Choisis le mdèle avec le meilleur score de validat° :\n",
    "best_tfidf_model = LogisticRegression(max_iter=1000)\n",
    "best_tfidf_model.fit(tfidf_vectorizer.fit_transform(X_train), y_train)\n",
    "\n",
    "# Prédict° sur l'ensble de test :\n",
    "y_pred_tfidf = best_tfidf_model.predict(tfidf_vectorizer.transform(X_test))\n",
    "\n",
    "# Évaluat° finale sur l'ensble de test :\n",
    "print(\"\\nClassification Report pour TfidfVectorizer :\")\n",
    "print(classification_report(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d9f6be16-3530-40a1-ad68-605a3aaa604f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report pour TfidfVectorizer :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.58      0.64      1944\n",
      "     neutral       0.64      0.72      0.68      2772\n",
      "    positive       0.74      0.74      0.74      2154\n",
      "\n",
      "    accuracy                           0.69      6870\n",
      "   macro avg       0.70      0.68      0.69      6870\n",
      "weighted avg       0.69      0.69      0.69      6870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Évaluat° du mdèle final :\n",
    "# Choisis le mdèle avec le meilleur score de validat° :\n",
    "best_model = grid_search_tfidf.best_estimator_\n",
    "\n",
    "# Prédict° sur l'ensble de test :\n",
    "y_pred_tfidf = best_model.predict(X_test)\n",
    "\n",
    "# Affiche le rapport de classificat° pr TfidfVectorizer :\n",
    "print(\"\\nClassification Report pour TfidfVectorizer :\")\n",
    "print(classification_report(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0509d0da-d45b-4e7d-b499-7c201ab48eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
