{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b0ed7218-226d-4b60-b1e4-d83f4a48cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "98eebc74-01d2-4eea-9694-c939e96e00fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3d65d95a-43b2-41c6-9292-a9e396ca1af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27480, 4)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e87cf590-0826-4e21-9c5f-a0a80a07c8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6e0c6d75b1</td>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>fun</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27474</th>\n",
       "      <td>b78ec00df5</td>\n",
       "      <td>enjoy ur night</td>\n",
       "      <td>enjoy</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27475</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16363 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2      088c60f138                          my boss is bullying me...   \n",
       "3      9642c003ef                     what interview! leave me alone   \n",
       "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "6      6e0c6d75b1  2am feedings for the baby are fun when he is a...   \n",
       "...           ...                                                ...   \n",
       "27474  b78ec00df5                                     enjoy ur night   \n",
       "27475  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27476  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27477  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27478  ed167662a5                         But it was worth it  ****.   \n",
       "\n",
       "                    selected_text sentiment  \n",
       "1                        Sooo SAD  negative  \n",
       "2                     bullying me  negative  \n",
       "3                  leave me alone  negative  \n",
       "4                   Sons of ****,  negative  \n",
       "6                             fun  positive  \n",
       "...                           ...       ...  \n",
       "27474                       enjoy  positive  \n",
       "27475                      d lost  negative  \n",
       "27476               , don`t force  negative  \n",
       "27477   Yay good for both of you.  positive  \n",
       "27478  But it was worth it  ****.  positive  \n",
       "\n",
       "[16363 rows x 4 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtre le DataFrame pr Ã©liminer les lignes oÃ¹ 'neutral' apparait : \n",
    "df_filtered = df[df['sentiment'] != 'neutral']\n",
    "\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eba8a311-6947-4693-a7d9-b4a499e60353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16363, 4)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "33f6237a-30e8-437d-b3d5-a7c345b8e7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    52.447595\n",
       "negative    47.552405\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcule la frÃ©qce des sentimts :\n",
    "sentiment = df_filtered['sentiment'].value_counts()\n",
    "\n",
    "# Calcule le % de chaq sentimt :\n",
    "sentiment_pourcent = (sentiment / sentiment.sum()) * 100\n",
    "\n",
    "sentiment_pourcent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d72e04f3-e0d9-4082-bad8-d0e068036e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sebla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sebla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sebla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# TÃ©lÃ©chrge les ressrces nÃ©cessaires :\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialise le lemmatiseur et les stopwords :\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('french'))\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "# Â¨PrÃ©traitemt du texte :\n",
    "def clean(text):\n",
    "    \"\"\"\n",
    "    Fonction de nettoyage d'un texte : \n",
    "    - Tokenisation\n",
    "    - Conversion en minuscules\n",
    "    - Suppression des stopwords et de la ponctuation\n",
    "    - Application du lemmatiseur\n",
    "\n",
    "    :param text: Texte Ã  nettoyer (str)\n",
    "    :return: Texte nettoyÃ© sous forme de tokens (str)\n",
    "    \"\"\"\n",
    "\n",
    "    # TokenisatÂ° :\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # CversÂ° en minuscules et suppressÂ° des mots vides :\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha() and token.lower() not in stop_words]\n",
    "    \n",
    "    # RecpositÂ° du texte nettoyÃ© ss frme de chaÃ®ne avec des espaces entre les tokens :\n",
    "    cleaned_text = \" \".join(tokens)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "435c4884-eecc-4704-8b3e-a7f8aa542154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original:\n",
      "You are better when I am well !\n",
      "\n",
      "Texte nettoyÃ© (lemmatisÃ©):\n",
      "you are better when i am well\n"
     ]
    }
   ],
   "source": [
    "# Test :\n",
    "texte = \"You are better when I am well !\"\n",
    "texte_nettoye = clean(texte)\n",
    "\n",
    "print(\"Texte original:\")\n",
    "print(texte)\n",
    "\n",
    "print(\"\\nTexte nettoyÃ© (lemmatisÃ©):\")\n",
    "print(texte_nettoye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3c93eb10-1b60-466d-81e9-7f3e21effedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise du stemmer :\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def clean_stemmer(text):\n",
    "    \"\"\"\n",
    "    Fonction de nettoyage d'un texte avec un stemmer :\n",
    "    - Tokenisation\n",
    "    - Conversion en minuscules\n",
    "    - Suppression des stopwords et de la ponctuation\n",
    "    - Application du stemmer\n",
    "\n",
    "    :param text: Texte Ã  nettoyer (str)\n",
    "    :return: Texte nettoyÃ© sous forme de tokens (str)\n",
    "    \"\"\"\n",
    "    # TokenisatÂ° des mots :\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # PrÃ©traitemt des tokens : suppressÂ° des mots vides, ponctuatÂ° et conversÂ° en minuscules :\n",
    "    tokens = [stemmer.stem(token.lower()) for token in tokens if token.isalpha() and token.lower() not in stop_words]\n",
    "    \n",
    "    # RecpositÂ° du texte nettoyÃ© ss frme de chaÃ®ne avec des espaces entre les tokens :\n",
    "    cleaned_text = \" \".join(tokens)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "50507814-27e8-48d3-9489-a922dc8ed4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original:\n",
      "You are better when I am well !\n",
      "\n",
      "Texte nettoyÃ© (stemmer):\n",
      "you are better when i am well\n"
     ]
    }
   ],
   "source": [
    "# Test :\n",
    "texte = \"You are better when I am well !\"\n",
    "texte_nettoye = clean(texte)\n",
    "\n",
    "print(\"Texte original:\")\n",
    "print(texte)\n",
    "\n",
    "print(\"\\nTexte nettoyÃ© (stemmer):\")\n",
    "print(texte_nettoye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f0b6153d-f8cf-437d-9a4b-8ecea66defa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise le lemmatiseur :\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# RÃ©cupÃ©re les stopwords anglais :\n",
    "stopwordsenglish = set(stopwords.words('english'))\n",
    "\n",
    "# PonctuatÂ° Ã  exclure :\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "def clean(text):\n",
    "    \"\"\"\n",
    "    Fonction de nettoyage d'un texte :\n",
    "    - Tokenisation\n",
    "    - Conversion en minuscules\n",
    "    - Suppression des stopwords en franÃ§ais et anglais\n",
    "    - Suppression de la ponctuation\n",
    "    - Application du lemmatiseur\n",
    "\n",
    "    :param text: Texte Ã  nettoyer (str)\n",
    "    :return: Texte nettoyÃ© sous forme de tokens (str)\n",
    "    \"\"\"\n",
    "    # TokenisatÂ° des mots :\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # PrÃ©traitemt des tokens :\n",
    "    # - SuppressÂ° des mots vides (stopwords en anglais et en franÃ§ais)\n",
    "    # - SuppressÂ° des signes de ponctuatÂ°\n",
    "    # - ConversÂ° en minuscules et lemmatisatÂ°\n",
    "    tokens = [\n",
    "        lemmatizer.lemmatize(token.lower()) \n",
    "        for token in tokens \n",
    "        if token.isalpha() and token.lower() not in stopwordsenglish and token.lower() not in stopwords.words('french') and token not in punctuation\n",
    "    ]\n",
    "    \n",
    "    # Recpose le texte nettoyÃ© ss frme de chaÃ®ne avec des espaces entre les tokens :\n",
    "    cleaned_text = \" \".join(tokens)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9fd69443-5848-4de0-82dd-ba08a57048d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original:\n",
      "The children are eating apples, and they are playing in the park!\n",
      "\n",
      "Texte nettoyÃ©:\n",
      "child eating apple playing park\n"
     ]
    }
   ],
   "source": [
    "# Test :\n",
    "texte = \"The children are eating apples, and they are playing in the park!\"\n",
    "\n",
    "# Appliq la fctÂ° clean :\n",
    "texte_nettoye = clean(texte)\n",
    "\n",
    "print(\"Texte original:\")\n",
    "print(texte)\n",
    "\n",
    "print(\"\\nTexte nettoyÃ©:\")\n",
    "print(texte_nettoye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6000746e-109e-4cfa-a755-75e6136e7b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>responded going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>sooo sad miss san diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bos bullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>interview leave alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>son put release already bought</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                I`d have responded, if I were going   \n",
       "1      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                          my boss is bullying me...   \n",
       "3                     what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                            clean  \n",
       "0                 responded going  \n",
       "1         sooo sad miss san diego  \n",
       "2                    bos bullying  \n",
       "3           interview leave alone  \n",
       "4  son put release already bought  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appliq la fctÂ° 'clean' Ã  chaq Ã©lÃ©mt de la colonne 'text'\n",
    "df['clean'] = df['text'].apply(clean)\n",
    "\n",
    "# Affiche le DataFrame avec la nvelle colonne 'clean' :\n",
    "df[['text', 'clean']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c1408b1d-53a5-4e10-b647-2cca5765aece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraÃ®nement (X_train, y_train): 20610\n",
      "Taille de l'ensemble de test (X_test, y_test): 6870\n"
     ]
    }
   ],
   "source": [
    "# Copie la colonne 'clean' ds 1 sÃ©rie X (caractÃ©ristiq d'entrÃ©e) :\n",
    "X = df['clean']\n",
    "\n",
    "# Copie la colonne 'sentimt' ds 1 sÃ©rie y (labels de sortie) :\n",
    "y = df['sentiment']\n",
    "\n",
    "# Appliq train-test split :\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=32)\n",
    "\n",
    "print(\"Taille de l'ensemble d'entraÃ®nement (X_train, y_train):\", len(X_train))\n",
    "print(\"Taille de l'ensemble de test (X_test, y_test):\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "324b8659-f1b2-4906-8d5c-2db16b8c9f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy du modÃ¨le : 0.6902\n"
     ]
    }
   ],
   "source": [
    "# CrÃ©er 1 mdÃ¨le CountVectorizer :\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# EntraÃ®ne le mdÃ¨le sur X_train et crÃ©er la matrice de caractÃ©ristiq X_train_CV :\n",
    "X_train_CV = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# CrÃ©er la matrice de caractÃ©ristiq X_test_CV en utilisant le mÃªme mdÃ¨le sans rÃ©entraÃ®ner :\n",
    "X_test_CV = vectorizer.transform(X_test)\n",
    "\n",
    "# EntraÃ®ner 1 mdÃ¨le de rÃ©gressÂ° logistiq sur les donnÃ©es vectorisÃ©es\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_CV, y_train)\n",
    "\n",
    "# PrÃ©dis sur l'ensble de test :\n",
    "y_pred_CV = model.predict(X_test_CV)\n",
    "\n",
    "# Ã‰valuatÂ° du mdÃ¨le :\n",
    "accuracy_CV = accuracy_score(y_test, y_pred_CV)\n",
    "print(f\"Accuracy du modÃ¨le : {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c0240837-a542-4cf6-aaae-d373ef970d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy du modÃ¨le : 0.6902\n",
      "RÃ©sultats pour CountVectorizer :\n",
      "Accuracy (CountVectorizer) : 0.6902\n",
      "\n",
      "Classification Report (CountVectorizer) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.61      0.65      1944\n",
      "     neutral       0.64      0.72      0.68      2772\n",
      "    positive       0.75      0.72      0.74      2154\n",
      "\n",
      "    accuracy                           0.69      6870\n",
      "   macro avg       0.70      0.68      0.69      6870\n",
      "weighted avg       0.69      0.69      0.69      6870\n",
      "\n",
      "\n",
      "RÃ©sultats pour TfidfVectorizer :\n",
      "Accuracy (TfidfVectorizer) : 0.5622\n",
      "\n",
      "Classification Report (TfidfVectorizer) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.32      0.46      1944\n",
      "     neutral       0.48      0.94      0.64      2772\n",
      "    positive       0.90      0.29      0.44      2154\n",
      "\n",
      "    accuracy                           0.56      6870\n",
      "   macro avg       0.73      0.52      0.51      6870\n",
      "weighted avg       0.71      0.56      0.53      6870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CrÃ©er 1 mdÃ¨le TfidfVectorizer :\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# EntraÃ®ne le mdÃ¨le sur X_train et crÃ©er la matrice de caractÃ©ristiq X_train_CV :\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# CrÃ©er la matrice de caractÃ©ristiq X_test_CV en utilisant le mÃªme mdÃ¨le sans rÃ©entraÃ®ner :\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# EntraÃ®ner 1 mdÃ¨le de rÃ©gressÂ° logistiq sur les donnÃ©es vectorisÃ©es\n",
    "model_tfidf = LogisticRegression(max_iter=1000)\n",
    "model_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# PrÃ©dis sur l'ensble de test :\n",
    "y_pred_tfidf = model.predict(X_test_tfidf)\n",
    "\n",
    "# Ã‰valuatÂ° du mdÃ¨le :\n",
    "accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "print(f\"Accuracy du modÃ¨le : {accuracy:.4f}\")\n",
    "\n",
    "# Affiche des rÃ©sultats de cparaisÂ° :\n",
    "print(\"RÃ©sultats pour CountVectorizer :\")\n",
    "print(f\"Accuracy (CountVectorizer) : {accuracy_CV:.4f}\")\n",
    "print(\"\\nClassification Report (CountVectorizer) :\")\n",
    "print(classification_report(y_test, y_pred_CV))\n",
    "\n",
    "print(\"\\nRÃ©sultats pour TfidfVectorizer :\")\n",
    "print(f\"Accuracy (TfidfVectorizer) : {accuracy_tfidf:.4f}\")\n",
    "print(\"\\nClassification Report (TfidfVectorizer) :\")\n",
    "print(classification_report(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1fb153-01c3-4d34-9d1a-8ccafdbc5393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les meilleurs paramÃ¨tres sont obtenus avec le modÃ¨le de CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bdf4bc8e-5d87-48b4-a2f6-575fadba7403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Meilleurs pramÃ¨tres pr CountVectorizer :\n",
      "{'vectorizer__max_df': 0.75, 'vectorizer__min_df': 1, 'vectorizer__ngram_range': (1, 2), 'vectorizer__stop_words': 'english'}\n",
      "Meilleur score de validation : 0.6923\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "\n",
      "Meilleurs paramÃ¨tres pour TfidfVectorizer :\n",
      "{'vectorizer__max_df': 0.75, 'vectorizer__min_df': 1, 'vectorizer__ngram_range': (1, 2), 'vectorizer__stop_words': 'english'}\n",
      "Meilleur score de validation : 0.6882\n"
     ]
    }
   ],
   "source": [
    "# SÃ©paratÂ° des donnÃ©es en jeu d'entraÃ®nemt et de test :\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=32)\n",
    "\n",
    "# PramÃ¨tres Ã  tester pr CountVectorizer et TfidfVectorizer :\n",
    "param_grid_cv = {\n",
    "    'vectorizer__max_df': [0.75, 1.0],  # Ignore les mots apparaissant ds + de 75% des documts\n",
    "    'vectorizer__min_df': [1, 5],  # Ignore les mots apparaissant ds - de 5 documts\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],  # Unigrammes ou Bigrammes\n",
    "    'vectorizer__stop_words': ['english', None]  # Utilise les stopwords anglais ou pas\n",
    "}\n",
    "\n",
    "param_grid_tfidf = {\n",
    "    'vectorizer__max_df': [0.75, 1.0],\n",
    "    'vectorizer__min_df': [1, 5],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vectorizer__stop_words': ['english', None]\n",
    "}\n",
    "\n",
    "# Pipeline avec CountVectorizer :\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# CrÃ©atÂ° du Pipeline pr CountVectorizer :\n",
    "pipeline_cv = Pipeline([\n",
    "    ('vectorizer', count_vectorizer),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))  # RÃ©gressÂ° logistiq\n",
    "])\n",
    "\n",
    "# GridSearchCV pr CountVectorizer avec RÃ©gressÂ° logistiq :\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=pipeline_cv, \n",
    "    param_grid=param_grid_cv, \n",
    "    cv=5,  # 5-fold Cross-validatÂ°\n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,  # Utiliser ts les cÅ“urs de CPU\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Apprentissage avec GridSearchCV pr CountVectorizer :\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "# Affiche les meilleurs pramÃ¨tres trvÃ©s :\n",
    "print(\"Meilleurs pramÃ¨tres pr CountVectorizer :\")\n",
    "print(grid_search_cv.best_params_)\n",
    "print(f\"Meilleur score de validation : {grid_search_cv.best_score_:.4f}\")\n",
    "\n",
    "# Pipeline avec TfidfVectorizer :\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# CrÃ©atÂ° du Pipeline pr TfidfVectorizer :\n",
    "pipeline_tfidf = Pipeline([\n",
    "    ('vectorizer', tfidf_vectorizer),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))  # RÃ©gressÂ° logistiq\n",
    "])\n",
    "\n",
    "# GridSearchCV pr TfidfVectorizer avec RÃ©gressÂ° logistiq\n",
    "grid_search_tfidf = GridSearchCV(\n",
    "    estimator=pipeline_tfidf, \n",
    "    param_grid=param_grid_tfidf, \n",
    "    cv=5, \n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Apprentissage avec GridSearchCV pr TfidfVectorizer :\n",
    "grid_search_tfidf.fit(X_train, y_train)\n",
    "\n",
    "# Affiche les meilleurs pramÃ¨tres trvÃ©s :\n",
    "print(\"\\nMeilleurs paramÃ¨tres pour TfidfVectorizer :\")\n",
    "print(grid_search_tfidf.best_params_)\n",
    "print(f\"Meilleur score de validation : {grid_search_tfidf.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "506c5e88-1e7a-4160-9e2c-36a2024f4236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation Scores pour CountVectorizer :\n",
      "[0.68558952 0.69311014 0.6768559  0.69335274 0.68073751]\n",
      "Moyenne Cross-validation : 0.6859\n",
      "\n",
      "Cross-validation Scores pour TfidfVectorizer :\n",
      "[0.6780689  0.68753033 0.67564289 0.68680252 0.67540029]\n",
      "Moyenne Cross-validation : 0.6807\n"
     ]
    }
   ],
   "source": [
    "# Cross-validatÂ° pr Ã©valuer les mdÃ¨les afin de trver les meilleurs pramÃ¨tres :\n",
    "# Cross-validatÂ° pr CountVectorizer :\n",
    "cv_score_cv = cross_val_score(\n",
    "    LogisticRegression(max_iter=1000), \n",
    "    count_vectorizer.fit_transform(X_train), \n",
    "    y_train, \n",
    "    cv=5, \n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "print(\"\\nCross-validation Scores pour CountVectorizer :\")\n",
    "print(cv_score_cv)\n",
    "print(f\"Moyenne Cross-validation : {cv_score_cv.mean():.4f}\")\n",
    "\n",
    "\n",
    "# Cross-validatÂ° pr TfidfVectorizer :\n",
    "cv_score_tfidf = cross_val_score(\n",
    "    LogisticRegression(max_iter=1000), \n",
    "    tfidf_vectorizer.fit_transform(X_train), \n",
    "    y_train, \n",
    "    cv=5, \n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "print(\"\\nCross-validation Scores pour TfidfVectorizer :\")\n",
    "print(cv_score_tfidf)\n",
    "print(f\"Moyenne Cross-validation : {cv_score_tfidf.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1262c000-4620-4c4d-8f6c-2a892cac2087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report pour TfidfVectorizer :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.59      0.65      1944\n",
      "     neutral       0.63      0.74      0.68      2772\n",
      "    positive       0.76      0.71      0.73      2154\n",
      "\n",
      "    accuracy                           0.69      6870\n",
      "   macro avg       0.70      0.68      0.69      6870\n",
      "weighted avg       0.70      0.69      0.69      6870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# EntraÃ®nemt final sur le meilleur modÃ¨le :\n",
    "# Choisis le mdÃ¨le avec le meilleur score de validatÂ° :\n",
    "best_tfidf_model = LogisticRegression(max_iter=1000)\n",
    "best_tfidf_model.fit(tfidf_vectorizer.fit_transform(X_train), y_train)\n",
    "\n",
    "# PrÃ©dictÂ° sur l'ensble de test :\n",
    "y_pred_tfidf = best_tfidf_model.predict(tfidf_vectorizer.transform(X_test))\n",
    "\n",
    "# Ã‰valuatÂ° finale sur l'ensble de test :\n",
    "print(\"\\nClassification Report pour TfidfVectorizer :\")\n",
    "print(classification_report(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d9f6be16-3530-40a1-ad68-605a3aaa604f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report pour TfidfVectorizer :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.58      0.64      1944\n",
      "     neutral       0.64      0.72      0.68      2772\n",
      "    positive       0.74      0.74      0.74      2154\n",
      "\n",
      "    accuracy                           0.69      6870\n",
      "   macro avg       0.70      0.68      0.69      6870\n",
      "weighted avg       0.69      0.69      0.69      6870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ã‰valuatÂ° du mdÃ¨le final :\n",
    "# Choisis le mdÃ¨le avec le meilleur score de validatÂ° :\n",
    "best_model = grid_search_tfidf.best_estimator_\n",
    "\n",
    "# PrÃ©dictÂ° sur l'ensble de test :\n",
    "y_pred_tfidf = best_model.predict(X_test)\n",
    "\n",
    "# Affiche le rapport de classificatÂ° pr TfidfVectorizer :\n",
    "print(\"\\nClassification Report pour TfidfVectorizer :\")\n",
    "print(classification_report(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0509d0da-d45b-4e7d-b499-7c201ab48eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
